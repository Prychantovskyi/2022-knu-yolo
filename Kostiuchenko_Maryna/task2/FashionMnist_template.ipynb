{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4b9b8a",
   "metadata": {},
   "source": [
    "# Train NN model on the FashionMNIST data\n",
    "\n",
    "https://www.kaggle.com/zalando-research/fashionmnist\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "You may refer to this tutorial about the original Mnist:\n",
    "https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
    "\n",
    "Or any other tutorial you may find online:\n",
    "https://www.kaggle.com/zalando-research/fashionmnist/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a60fad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c19eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "016674dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "# Lets see all the classes available\n",
    "class_names = training_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "605d1835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lest read a random image from the dataset and draw it\n",
    "image, label = training_data[17]\n",
    "plt.imshow(image[0], \"gray\")\n",
    "plt.title(f\"Image of class: {class_names[label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f490ddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check image shape\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a7f78",
   "metadata": {},
   "source": [
    "# Task 1:\n",
    "\n",
    "Create a DataLoader objects for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "97c9881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(training_data, batch_size=100, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "78370e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695343f",
   "metadata": {},
   "source": [
    "# Task 2:\n",
    "\n",
    "Create a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "56d2dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=784, out_features=196, bias=True)\n",
      "  (fc2): Linear(in_features=196, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 196)\n",
    "        self.fc2 = nn.Linear(196, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim = 1)\n",
    "\n",
    "\n",
    "model = NN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d5117",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "\n",
    "Specify loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "322c13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d2ab0",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "\n",
    "Train model using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "34fd7fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training loss: 0.5606488247215747 Training Accuracy: 80%\n",
      "Epoch: 2 Training loss: 0.38752343468368056 Training Accuracy: 86%\n",
      "Epoch: 3 Training loss: 0.3475873604416847 Training Accuracy: 87%\n",
      "Epoch: 4 Training loss: 0.31841019526124 Training Accuracy: 88%\n",
      "Epoch: 5 Training loss: 0.29947142812112965 Training Accuracy: 89%\n",
      "Epoch: 6 Training loss: 0.2819151672720909 Training Accuracy: 90%\n",
      "Epoch: 7 Training loss: 0.26957687497138977 Training Accuracy: 90%\n",
      "Epoch: 8 Training loss: 0.2571938425550858 Training Accuracy: 90%\n",
      "Epoch: 9 Training loss: 0.24543533443162838 Training Accuracy: 91%\n",
      "Epoch: 10 Training loss: 0.236136999775966 Training Accuracy: 91%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0\n",
    "    correct_epoch = 0\n",
    "    for batch, (X, y) in enumerate(trainloader):\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        X = X.view(-1, 784)\n",
    "        \n",
    "        out = model.forward(X)\n",
    "        loss = loss_fn(out, y)\n",
    "        \n",
    "        _, preds = torch.max(out, dim=1)\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        correct_epoch += (preds == y).float().sum()\n",
    "       \n",
    "    running_loss = running_loss / len(trainloader)\n",
    "    acc = correct_epoch / len(training_data)\n",
    "    print(\"Epoch: {}\".format(epoch+1),\n",
    "          \"Training loss: {}\".format(running_loss),\n",
    "          \"Training Accuracy: {:.0f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d61b00",
   "metadata": {},
   "source": [
    "# Task 4:\n",
    "\n",
    "Report accuracy from train set, and test set independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3b95249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3180987536907196 Test Accuracy: 89%\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "preds_test = torch.tensor([])\n",
    "vals_test  = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for X, y in valloader:\n",
    "        X = X.view(-1, 784)\n",
    "        out = model.forward(X)\n",
    "        test_loss += loss_fn(out, y)\n",
    "        _, preds = torch.max(out, dim=1)\n",
    "        correct += (preds == y).float().sum()\n",
    "        preds_test = torch.cat((preds_test, model.forward(X)), 0)\n",
    "        vals_test  = torch.cat((vals_test , y), 0)\n",
    "\n",
    "test_loss /= len(valloader)\n",
    "test_acc = correct / len(test_data)\n",
    "print(\"Test loss: {:}\".format(test_loss),\n",
    "          \"Test Accuracy: {:.0f}%\".format(100*test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcc3eb",
   "metadata": {},
   "source": [
    "# Task 5:\n",
    "\n",
    "Report confussion matrix for the test set\n",
    "\n",
    "Expected format:\n",
    "```\n",
    "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7b84ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[827   2  22  38   2   2 100   0   7   0]\n",
      " [  1 975   2  18   1   0   2   0   1   0]\n",
      " [ 12   1 846  16  62   1  61   0   1   0]\n",
      " [ 12   5   9 922  25   0  24   0   3   0]\n",
      " [  0   0 107  39 760   0  91   0   3   0]\n",
      " [  0   0   0   0   0 974   0  15   0  11]\n",
      " [101   2  90  39  52   0 706   0  10   0]\n",
      " [  0   0   0   0   0  24   0 932   0  44]\n",
      " [  3   1   6   8   5   4   2   5 966   0]\n",
      " [  0   0   0   0   0   9   1  32   0 958]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "_, preds = torch.max(preds_test, dim=1)\n",
    "conf_mat = confusion_matrix(vals_test.numpy(), preds.numpy())\n",
    "print('Confusion matrix')\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a7f90",
   "metadata": {},
   "source": [
    "# Task 6 (optional):\n",
    "\n",
    "Train LogisticRegression and DecisionTree models on the same data\n",
    "Compare their performance to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e6ceba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 784)\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a0e0d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n"
     ]
    }
   ],
   "source": [
    "log_regression = LogisticRegression()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch, (X, y) in enumerate(trainloader):\n",
    "        X, y = Variable(X), Variable(y)\n",
    "        X = X.view(-1, 784)\n",
    "      \n",
    "        log_out = log_regression.forward(X)\n",
    "        loss = loss_fn(log_out, y)\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: {}\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8ecbd8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression 0.09929999709129333\n"
     ]
    }
   ],
   "source": [
    "log_preds = torch.tensor([])\n",
    "with torch.no_grad():\n",
    "    for (X, y) in valloader:\n",
    "        log_preds = torch.cat((log_preds, log_regression.forward(X)), 0)\n",
    "        \n",
    "_, preds = torch.max(log_preds, dim=1)\n",
    "log_acc = torch.tensor(torch.sum(preds == vals_test).item() / len(preds))    \n",
    "print(\"Accuracy of logistic regression {}\".format(log_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d42e8c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_dataset_array = training_data.data.numpy()\n",
    "train_dataset_array = train_dataset_array.reshape(-1, 784)\n",
    "training_dataset_labels = training_data.targets.numpy()\n",
    "\n",
    "test_dataset_array = test_data.data.numpy()\n",
    "test_dataset_array = test_dataset_array.reshape(-1, 784)\n",
    "test_dataset_labels = test_data.targets.numpy()\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_dataset_array, training_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "aa7d5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of decision tree 79%\n"
     ]
    }
   ],
   "source": [
    "decision_tree_preds = decision_tree.predict(test_dataset_array)\n",
    "decision_tree_acc = (decision_tree_preds == test_dataset_labels).sum() / len(decision_tree_preds)\n",
    "print(\"Accuracy of decision tree {:.0f}%\".format(100*decision_tree_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b91dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
